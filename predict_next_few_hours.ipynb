{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import requests\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length=5):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size * 3, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * 3, hidden_size * 2)\n",
    "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size * 1)\n",
    "        self.fc2 = nn.Linear(hidden_size * 1, num_classes)\n",
    "        # self.fc3 = nn.Linear(hidden_size * 1, hidden_size // 2)\n",
    "        # self.fc4 = nn.Linear(hidden_size // 2, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size * 3))\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size * 3))\n",
    "\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        h_out = h_out.view(-1, self.hidden_size * 3)\n",
    "        out = self.fc(h_out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "[[2265.99520793]\n",
      " [4403.40378086]\n",
      " [6048.88734619]\n",
      " [7458.98336172]\n",
      " [8859.07496611]\n",
      " [8888.36633762]\n",
      " [9929.72326279]\n",
      " [8998.76856804]\n",
      " [7743.85716915]\n",
      " [5519.99815702]\n",
      " [6712.65929937]\n",
      " [5613.74697685]]\n",
      "[[4977.94]]\n"
     ]
    }
   ],
   "source": [
    "seq_length = 12\n",
    "lstm = LSTM(1, 1, 1, 1, seq_length)\n",
    "lstm.load_state_dict(torch.load(\"models/energy_usage_predictor.pth\"))\n",
    "\n",
    "lstm.eval()\n",
    "\n",
    "\n",
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data) - seq_length - 1):\n",
    "        _x = data[i:(i+seq_length)]\n",
    "        _y = data[i+seq_length]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "        break\n",
    "\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "# Get the last 144 points of 10 minute chunks (so if every 5 seconds, that is 4320) and predict what the prices will be\n",
    "response = requests.get(f\"http://144.39.204.242:11236/evr/leviton/evr?limit=2400\")\n",
    "usage = response.json()\n",
    "ten_minute_averages = {\"timestamp\": [], \"power\": []}\n",
    "\n",
    "for i in range(0, len(usage['data']), 85):\n",
    "    values = usage['data'][i:i+120]\n",
    "    power = [value['power'] for value in values]\n",
    "    ten_minute_averages[\"timestamp\"].append(values[0]['timestamp'])\n",
    "    ten_minute_averages[\"power\"].append(np.average(power) * 1000)\n",
    "    \n",
    "\n",
    "power = ten_minute_averages[\"power\"]\n",
    "power = [[i] for i in power]\n",
    "print(len(power))\n",
    "power = np.array(power)\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "power = sc.fit_transform(power)\n",
    "testNewX, testNewY = sliding_windows(power, seq_length)\n",
    "\n",
    "tensorX = torch.Tensor(testNewX)\n",
    "\n",
    "first_prediction = lstm(tensorX)\n",
    "print(sc.inverse_transform(testNewX[0]))\n",
    "print(sc.inverse_transform(first_prediction.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "first_prediction = lstm(tensorX)\n",
    "testNewX.pop()\n",
    "testNewX.append(first_prediction.data.numpy())\n",
    "for i in range(12):\n",
    "    tensorX = torch.Tensor(testNewX)\n",
    "    first_prediction = lstm(tensorX)\n",
    "    testNewX.pop()\n",
    "    testNewX.append(first_prediction.data.numpy())\n",
    "\n",
    "plt.plot(predictions)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
